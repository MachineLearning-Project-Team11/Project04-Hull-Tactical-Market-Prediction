{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":111543,"databundleVersionId":14348714,"sourceType":"competition"}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:55:55.099642Z","iopub.execute_input":"2025-12-04T14:55:55.099927Z","iopub.status.idle":"2025-12-04T14:55:57.520009Z","shell.execute_reply.started":"2025-12-04T14:55:55.099904Z","shell.execute_reply":"2025-12-04T14:55:57.518902Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/hull-tactical-market-prediction/train.csv\n/kaggle/input/hull-tactical-market-prediction/test.csv\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_inference_server.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/default_gateway.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/__init__.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/templates.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/base_gateway.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/relay.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/kaggle_evaluation.proto\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/__init__.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/kaggle_evaluation_pb2_grpc.py\n/kaggle/input/hull-tactical-market-prediction/kaggle_evaluation/core/generated/__init__.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nimport sys\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd\nimport pandas.api.types\nimport polars as pl\nfrom scipy.optimize import minimize\n\n# --- Metric Implementation ---\nMIN_INVESTMENT = 0\nMAX_INVESTMENT = 2\n\nclass ParticipantVisibleError(Exception):\n    pass\n\ndef score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str) -> float:\n    \"\"\"\n    Calculates a custom evaluation metric (volatility-adjusted Sharpe ratio).\n    \"\"\"\n    if not pandas.api.types.is_numeric_dtype(submission['prediction']):\n        raise ParticipantVisibleError('Predictions must be numeric')\n\n    solution = solution.copy()\n    solution['position'] = submission['prediction']\n\n    if solution['position'].max() > MAX_INVESTMENT:\n        print(f\"Warning: Position max {solution['position'].max()} > {MAX_INVESTMENT}\")\n    if solution['position'].min() < MIN_INVESTMENT:\n        print(f\"Warning: Position min {solution['position'].min()} < {MIN_INVESTMENT}\")\n\n    solution['strategy_returns'] = solution['risk_free_rate'] * (1 - solution['position']) + solution['position'] * solution['forward_returns']\n\n    # Calculate strategy's Sharpe ratio\n    strategy_excess_returns = solution['strategy_returns'] - solution['risk_free_rate']\n    strategy_excess_cumulative = (1 + strategy_excess_returns).prod()\n    strategy_mean_excess_return = (strategy_excess_cumulative) ** (1 / len(solution)) - 1\n    strategy_std = solution['strategy_returns'].std()\n\n    trading_days_per_yr = 252\n    if strategy_std == 0:\n        return 0.0 \n        \n    sharpe = strategy_mean_excess_return / strategy_std * np.sqrt(trading_days_per_yr)\n    strategy_volatility = float(strategy_std * np.sqrt(trading_days_per_yr) * 100)\n\n    # Calculate market return and volatility\n    market_excess_returns = solution['forward_returns'] - solution['risk_free_rate']\n    market_excess_cumulative = (1 + market_excess_returns).prod()\n    market_mean_excess_return = (market_excess_cumulative) ** (1 / len(solution)) - 1\n    market_std = solution['forward_returns'].std()\n\n    market_volatility = float(market_std * np.sqrt(trading_days_per_yr) * 100)\n\n    if market_volatility == 0:\n        return 0.0\n\n    # Calculate the volatility penalty\n    excess_vol = max(0, strategy_volatility / market_volatility - 1.2) if market_volatility > 0 else 0\n    vol_penalty = 1 + excess_vol\n\n    # Calculate the return penalty\n    return_gap = max(\n        0,\n        (market_mean_excess_return - strategy_mean_excess_return) * 100 * trading_days_per_yr,\n    )\n    return_penalty = 1 + (return_gap**2) / 100\n\n    # Adjust the Sharpe ratio by the volatility and return penalty\n    adjusted_sharpe = sharpe / (vol_penalty * return_penalty)\n    return min(float(adjusted_sharpe), 1_000_000)\n\n# --- Configuration & Environment Setup ---\nIS_KAGGLE = Path('/kaggle').exists()\n\nif IS_KAGGLE:\n    INPUT_DIR = Path('/kaggle/input/hull-tactical-market-prediction')\n    sys.path.append(str(INPUT_DIR))\nelse:\n    INPUT_DIR = Path('.')\n    sys.path.append(os.getcwd())\n\nimport kaggle_evaluation.default_inference_server\n\n# --- Data Loading ---\nTRAIN_PATH = INPUT_DIR / 'train.csv'\nTEST_PATH = INPUT_DIR / 'test.csv'\n\ndef load_data(path):\n    if not path.exists():\n        return None\n    df = pd.read_csv(path)\n    if 'date_id' in df.columns:\n        df = df.sort_values('date_id').reset_index(drop=True)\n    return df\n\n# --- Strategy Implementation ---\nclass MomentumStrategy:\n    def __init__(self):\n        self.prices = [1.0] # Start at 1.0\n        self.signal_mean = 0.0\n        self.signal_std = 1.0\n        # Optimization parameters\n        self.w_sma = 1.0\n        self.w_mom = 1.0\n        self.scale = 0.5\n        self.bias = 1.0\n        \n    def fit(self, train_df):\n        # 1. Reconstruct price history from training data\n        # train_df has 'forward_returns'. \n        # We need 'lagged_forward_returns' to simulate the test environment.\n        # lagged_ret[t] = forward_ret[t-1]\n        lagged_returns = train_df['forward_returns'].shift(1).fillna(0.0).values\n        \n        # Reconstruct prices: P[t] = P[t-1] * (1 + lagged_ret[t])\n        # We start with 1.0.\n        # cumprod works: (1+r1)*(1+r2)...\n        self.prices = np.cumprod(1 + lagged_returns).tolist()\n        \n        # 2. Calculate features on the whole history to get stats\n        price_series = pd.Series(self.prices)\n        \n        sma_21 = price_series.rolling(21).mean()\n        sma_63 = price_series.rolling(63).mean()\n        mom_5 = price_series.pct_change(5)\n        \n        # Base Signals\n        sma_ratio = (sma_21 / sma_63 - 1).fillna(0.0)\n        mom_5 = mom_5.fillna(0.0)\n        \n        # --- Optimization ---\n        print(\"Optimizing strategy parameters...\")\n        \n        # Prepare data for optimization\n        # We need to align with train_df for scoring\n        # train_df has 'forward_returns', 'risk_free_rate'\n        solution = train_df[['forward_returns', 'risk_free_rate']].copy()\n        \n        def objective(params):\n            w_s, w_m, sc, bi = params\n            \n            # Combine signals\n            raw = w_s * sma_ratio + w_m * mom_5\n            \n            # Normalize (using current mean/std of raw signal)\n            # Note: This is slightly circular if we re-calc mean/std every time.\n            # Let's just use raw signal directly and let scale/bias handle normalization implicitly.\n            # weight = clip(bias + scale * raw, 0, 2)\n            \n            weights = np.clip(bi + sc * raw, 0.0, 2.0)\n            \n            submission = pd.DataFrame({'prediction': weights})\n            \n            try:\n                # We want to MAXIMIZE score, so minimize NEGATIVE score\n                s = score(solution, submission, 'date_id')\n                return -s\n            except:\n                return 0.0\n                \n        # Initial guess: w_sma=1, w_mom=1, scale=50 (since raw is small), bias=1\n        # raw signal is approx 0.01-0.05 range. \n        # z-score was (raw - mean)/std. std is approx 0.03. So raw/std ~ 30 * raw.\n        # 0.5 * z_score ~ 15 * raw.\n        # So scale around 10-20 might be good.\n        x0 = [1.0, 1.0, 15.0, 1.0]\n        \n        # Bounds: weights can be negative (contrarian?), scale positive, bias around 1\n        # Let's allow flexibility\n        res = minimize(objective, x0, method='Nelder-Mead', tol=1e-4, options={'maxiter': 100})\n        \n        self.w_sma, self.w_mom, self.scale, self.bias = res.x\n        print(f\"Optimization result: {res.message}\")\n        print(f\"Best Score: {-res.fun:.4f}\")\n        print(f\"Params: w_sma={self.w_sma:.2f}, w_mom={self.w_mom:.2f}, scale={self.scale:.2f}, bias={self.bias:.2f}\")\n        \n        # Keep only the last 63 prices to minimize state size, \n        # but enough to calculate SMA_63 for the next incoming point.\n        self.prices = self.prices[-63:]\n\n    def predict_one(self, lagged_return):\n        # Update state\n        current_price = self.prices[-1] * (1 + lagged_return)\n        self.prices.append(current_price)\n        if len(self.prices) > 64: # Keep enough history\n            self.prices.pop(0)\n            \n        # Calculate features using current history\n        # We need the last 63 prices to calculate SMA63\n        # self.prices now has length up to 64 (if we popped)\n        \n        price_series = pd.Series(self.prices)\n        \n        # We want the feature for the *current* point (the last one)\n        curr_sma_21 = price_series.iloc[-21:].mean()\n        curr_sma_63 = price_series.iloc[-63:].mean()\n        \n        # Mom 5: Price(t) / Price(t-5) - 1\n        if len(self.prices) >= 6:\n            curr_mom_5 = self.prices[-1] / self.prices[-6] - 1\n        else:\n            curr_mom_5 = 0.0\n            \n        # Signal\n        if curr_sma_63 == 0:\n            sma_ratio = 0.0\n        else:\n            sma_ratio = curr_sma_21 / curr_sma_63 - 1\n            \n        # Apply optimized parameters\n        raw_signal = self.w_sma * sma_ratio + self.w_mom * curr_mom_5\n        weight = np.clip(self.bias + self.scale * raw_signal, 0.0, 2.0)\n        \n        return weight\n\n# Initialize Global Model\nmodel = MomentumStrategy()\n\n# --- API Predict Function ---\ndef predict(test: pl.DataFrame) -> float:\n    # The API passes a Polars DataFrame.\n    # It contains 'lagged_forward_returns' (or equivalent) if provided by the environment.\n    # If not, we assume 0.0 (which is bad, but safe).\n    \n    df = test.to_pandas()\n    \n    # Check for return column\n    col_name = 'lagged_forward_returns'\n    if col_name not in df.columns:\n        # Fallback: check for 'return'\n        if 'return' in df.columns:\n            col_name = 'return'\n        else:\n            col_name = None\n            \n    # We expect a single row or batch. The example suggests returning a single float.\n    # If batch, we might need to return a list? But the example returns float.\n    # This implies the gateway calls predict() one row at a time or expects one value per call.\n    # Let's assume single row for now based on the working example.\n    \n    lagged_ret = 0.0\n    if not df.empty:\n        row = df.iloc[0]\n        if col_name:\n            val = row.get(col_name, 0.0)\n            if not pd.isna(val):\n                lagged_ret = val\n            \n    w = model.predict_one(lagged_ret)\n    return float(w)\n\n# --- Main Execution ---\nif __name__ == \"__main__\":\n    print(\"Loading training data...\")\n    train_df = load_data(TRAIN_PATH)\n    \n    if train_df is None:\n        print(\"Train data not found. Exiting.\")\n        sys.exit(0)\n    \n    print(\"Fitting model...\")\n    model.fit(train_df)\n    \n    # Setup Inference Server\n    inference_server = kaggle_evaluation.default_inference_server.DefaultInferenceServer(predict)\n\n    if IS_KAGGLE:\n        if os.getenv('KAGGLE_IS_COMPETITION_RERUN'):\n            print(\"Starting inference server...\")\n            inference_server.serve()\n        else:\n            print(\"Running local gateway on Kaggle (Interactive)...\")\n            inference_server.run_local_gateway(\n                (str(INPUT_DIR),)\n            )\n    else:\n        print(\"Running locally...\")\n        try:\n            inference_server.run_local_gateway(\n                (str(INPUT_DIR),)\n            )\n        except Exception as e:\n            print(f\"Local gateway error: {e}\")\n            # Fallback: Manual generation\n            if TEST_PATH.exists():\n                print(\"Fallback: Generating submission.parquet manually...\")\n                test_df = load_data(TEST_PATH)\n                if test_df is not None:\n                    test_pl = pl.from_pandas(test_df)\n                    \n                    # Reset model state to end of train\n                    model.fit(train_df)\n                    \n                    # Manual loop for local file generation\n                    weights = []\n                    ids = []\n                    for i in range(len(test_pl)):\n                        row_pl = test_pl[i]\n                        w = predict(row_pl)\n                        weights.append(w)\n                        # Get ID\n                        row_pd = row_pl.to_pandas()\n                        id_val = row_pd['row_id'].iloc[0] if 'row_id' in row_pd.columns else row_pd['date_id'].iloc[0]\n                        ids.append(id_val)\n                        \n                    submission_pl = pl.DataFrame({'date_id': ids, 'prediction': weights})\n                    output_path = Path('submission.parquet')\n                    submission_pl.write_parquet(output_path)\n                    print(f\"Saved {output_path}\")\n        \n        if Path('submission.parquet').exists():\n            print(\"Success: submission.parquet generated.\")\n        else:\n            print(\"Warning: submission.parquet not found.\")\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-04T14:55:59.393291Z","iopub.execute_input":"2025-12-04T14:55:59.393726Z","iopub.status.idle":"2025-12-04T14:56:02.604390Z","shell.execute_reply.started":"2025-12-04T14:55:59.393696Z","shell.execute_reply":"2025-12-04T14:56:02.603033Z"}},"outputs":[{"name":"stdout","text":"Loading training data...\nFitting model...\nOptimizing strategy parameters...\nOptimization result: Maximum number of iterations has been exceeded.\nBest Score: 0.7187\nParams: w_sma=0.94, w_mom=-1.19, scale=31.86, bias=-0.65\nRunning local gateway on Kaggle (Interactive)...\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}